{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/jatinmittal0001/ner-bi-lstm-dealing-with-oov-words/notebook#Data-Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import random \n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "from sklearn.metrics import classification_report\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #           Word  POS Tag\n",
       "0  Sentence: 1      Thousands  NNS   O\n",
       "1          NaN             of   IN   O\n",
       "2          NaN  demonstrators  NNS   O\n",
       "3          NaN           have  VBP   O\n",
       "4          NaN        marched  VBN   O"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\"../../../Dataset/NER-Dataset/ner_dataset.csv\",encoding=\"latin1\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #           Word  POS Tag\n",
       "0  Sentence: 1      Thousands  NNS   O\n",
       "1  Sentence: 1             of   IN   O\n",
       "2  Sentence: 1  demonstrators  NNS   O\n",
       "3  Sentence: 1           have  VBP   O\n",
       "4  Sentence: 1        marched  VBN   O"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Sentence #']=data['Sentence #'].ffill(axis = 0) \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_func = lambda s: [(w,p, t) for w,p, t in zip(s[\"Word\"].values.tolist(),\n",
    "                                                       s['POS'].values.tolist(),\n",
    "                                                        s[\"Tag\"].values.tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Sentence_POS_Tag_Pair</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>[(Thousands, NNS, O), (of, IN, O), (demonstrat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 10</td>\n",
       "      <td>[(Iranian, JJ, B-gpe), (officials, NNS, O), (s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence: 100</td>\n",
       "      <td>[(Helicopter, NN, O), (gunships, NNS, O), (Sat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence: 1000</td>\n",
       "      <td>[(They, PRP, O), (left, VBD, O), (after, IN, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence: 10000</td>\n",
       "      <td>[(U.N., NNP, B-geo), (relief, NN, O), (coordin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Sentence #                              Sentence_POS_Tag_Pair\n",
       "0      Sentence: 1  [(Thousands, NNS, O), (of, IN, O), (demonstrat...\n",
       "1     Sentence: 10  [(Iranian, JJ, B-gpe), (officials, NNS, O), (s...\n",
       "2    Sentence: 100  [(Helicopter, NN, O), (gunships, NNS, O), (Sat...\n",
       "3   Sentence: 1000  [(They, PRP, O), (left, VBD, O), (after, IN, O...\n",
       "4  Sentence: 10000  [(U.N., NNP, B-geo), (relief, NN, O), (coordin..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_data=data.groupby(['Sentence #']).apply(agg_func).reset_index().rename(columns={0:'Sentence_POS_Tag_Pair'})\n",
    "agg_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_data['Sentence']=agg_data['Sentence_POS_Tag_Pair'].apply(lambda sentence:\" \".join([s[0] for s in sentence]))\n",
    "agg_data['POS']=agg_data['Sentence_POS_Tag_Pair'].apply(lambda sentence:\" \".join([s[1] for s in sentence]))\n",
    "agg_data['Tag']=agg_data['Sentence_POS_Tag_Pair'].apply(lambda sentence:\" \".join([s[2] for s in sentence]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47959, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Sentence_POS_Tag_Pair</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>[(Thousands, NNS, O), (of, IN, O), (demonstrat...</td>\n",
       "      <td>Thousands of demonstrators have marched throug...</td>\n",
       "      <td>NNS IN NNS VBP VBN IN NNP TO VB DT NN IN NNP C...</td>\n",
       "      <td>O O O O O O B-geo O O O O O B-geo O O O O O B-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 10</td>\n",
       "      <td>[(Iranian, JJ, B-gpe), (officials, NNS, O), (s...</td>\n",
       "      <td>Iranian officials say they expect to get acces...</td>\n",
       "      <td>JJ NNS VBP PRP VBP TO VB NN TO JJ JJ NNS IN DT...</td>\n",
       "      <td>B-gpe O O O O O O O O O O O O O O B-tim O O O ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence: 100</td>\n",
       "      <td>[(Helicopter, NN, O), (gunships, NNS, O), (Sat...</td>\n",
       "      <td>Helicopter gunships Saturday pounded militant ...</td>\n",
       "      <td>NN NNS NNP VBD JJ NNS IN DT NNP JJ NN , WRB JJ...</td>\n",
       "      <td>O O B-tim O O O O O B-geo O O O O O B-org O O ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence: 1000</td>\n",
       "      <td>[(They, PRP, O), (left, VBD, O), (after, IN, O...</td>\n",
       "      <td>They left after a tense hour-long standoff wit...</td>\n",
       "      <td>PRP VBD IN DT NN JJ NN IN NN NNS .</td>\n",
       "      <td>O O O O O O O O O O O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence: 10000</td>\n",
       "      <td>[(U.N., NNP, B-geo), (relief, NN, O), (coordin...</td>\n",
       "      <td>U.N. relief coordinator Jan Egeland said Sunda...</td>\n",
       "      <td>NNP NN NN NNP NNP VBD NNP , NNP , JJ CC JJ JJ ...</td>\n",
       "      <td>B-geo O O B-per I-per O B-tim O B-geo O B-gpe ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Sentence #                              Sentence_POS_Tag_Pair  \\\n",
       "0      Sentence: 1  [(Thousands, NNS, O), (of, IN, O), (demonstrat...   \n",
       "1     Sentence: 10  [(Iranian, JJ, B-gpe), (officials, NNS, O), (s...   \n",
       "2    Sentence: 100  [(Helicopter, NN, O), (gunships, NNS, O), (Sat...   \n",
       "3   Sentence: 1000  [(They, PRP, O), (left, VBD, O), (after, IN, O...   \n",
       "4  Sentence: 10000  [(U.N., NNP, B-geo), (relief, NN, O), (coordin...   \n",
       "\n",
       "                                            Sentence  \\\n",
       "0  Thousands of demonstrators have marched throug...   \n",
       "1  Iranian officials say they expect to get acces...   \n",
       "2  Helicopter gunships Saturday pounded militant ...   \n",
       "3  They left after a tense hour-long standoff wit...   \n",
       "4  U.N. relief coordinator Jan Egeland said Sunda...   \n",
       "\n",
       "                                                 POS  \\\n",
       "0  NNS IN NNS VBP VBN IN NNP TO VB DT NN IN NNP C...   \n",
       "1  JJ NNS VBP PRP VBP TO VB NN TO JJ JJ NNS IN DT...   \n",
       "2  NN NNS NNP VBD JJ NNS IN DT NNP JJ NN , WRB JJ...   \n",
       "3                 PRP VBD IN DT NN JJ NN IN NN NNS .   \n",
       "4  NNP NN NN NNP NNP VBD NNP , NNP , JJ CC JJ JJ ...   \n",
       "\n",
       "                                                 Tag  \n",
       "0  O O O O O O B-geo O O O O O B-geo O O O O O B-...  \n",
       "1  B-gpe O O O O O O O O O O O O O O B-tim O O O ...  \n",
       "2  O O B-tim O O O O O B-geo O O O O O B-org O O ...  \n",
       "3                              O O O O O O O O O O O  \n",
       "4  B-geo O O B-per I-per O B-tim O B-geo O B-gpe ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Sentence_POS_Tag_Pair</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "      <th>tokenised_sentences</th>\n",
       "      <th>tag_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>[(Thousands, NNS, O), (of, IN, O), (demonstrat...</td>\n",
       "      <td>Thousands of demonstrators have marched throug...</td>\n",
       "      <td>NNS IN NNS VBP VBN IN NNP TO VB DT NN IN NNP C...</td>\n",
       "      <td>O O O O O O B-geo O O O O O B-geo O O O O O B-...</td>\n",
       "      <td>[Thousands, of, demonstrators, have, marched, ...</td>\n",
       "      <td>[O, O, O, O, O, O, B-geo, O, O, O, O, O, B-geo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 10</td>\n",
       "      <td>[(Iranian, JJ, B-gpe), (officials, NNS, O), (s...</td>\n",
       "      <td>Iranian officials say they expect to get acces...</td>\n",
       "      <td>JJ NNS VBP PRP VBP TO VB NN TO JJ JJ NNS IN DT...</td>\n",
       "      <td>B-gpe O O O O O O O O O O O O O O B-tim O O O ...</td>\n",
       "      <td>[Iranian, officials, say, they, expect, to, ge...</td>\n",
       "      <td>[B-gpe, O, O, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence: 100</td>\n",
       "      <td>[(Helicopter, NN, O), (gunships, NNS, O), (Sat...</td>\n",
       "      <td>Helicopter gunships Saturday pounded militant ...</td>\n",
       "      <td>NN NNS NNP VBD JJ NNS IN DT NNP JJ NN , WRB JJ...</td>\n",
       "      <td>O O B-tim O O O O O B-geo O O O O O B-org O O ...</td>\n",
       "      <td>[Helicopter, gunships, Saturday, pounded, mili...</td>\n",
       "      <td>[O, O, B-tim, O, O, O, O, O, B-geo, O, O, O, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence: 1000</td>\n",
       "      <td>[(They, PRP, O), (left, VBD, O), (after, IN, O...</td>\n",
       "      <td>They left after a tense hour-long standoff wit...</td>\n",
       "      <td>PRP VBD IN DT NN JJ NN IN NN NNS .</td>\n",
       "      <td>O O O O O O O O O O O</td>\n",
       "      <td>[They, left, after, a, tense, hour-long, stand...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence: 10000</td>\n",
       "      <td>[(U.N., NNP, B-geo), (relief, NN, O), (coordin...</td>\n",
       "      <td>U.N. relief coordinator Jan Egeland said Sunda...</td>\n",
       "      <td>NNP NN NN NNP NNP VBD NNP , NNP , JJ CC JJ JJ ...</td>\n",
       "      <td>B-geo O O B-per I-per O B-tim O B-geo O B-gpe ...</td>\n",
       "      <td>[U.N., relief, coordinator, Jan, Egeland, said...</td>\n",
       "      <td>[B-geo, O, O, B-per, I-per, O, B-tim, O, B-geo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Sentence #                              Sentence_POS_Tag_Pair  \\\n",
       "0      Sentence: 1  [(Thousands, NNS, O), (of, IN, O), (demonstrat...   \n",
       "1     Sentence: 10  [(Iranian, JJ, B-gpe), (officials, NNS, O), (s...   \n",
       "2    Sentence: 100  [(Helicopter, NN, O), (gunships, NNS, O), (Sat...   \n",
       "3   Sentence: 1000  [(They, PRP, O), (left, VBD, O), (after, IN, O...   \n",
       "4  Sentence: 10000  [(U.N., NNP, B-geo), (relief, NN, O), (coordin...   \n",
       "\n",
       "                                            Sentence  \\\n",
       "0  Thousands of demonstrators have marched throug...   \n",
       "1  Iranian officials say they expect to get acces...   \n",
       "2  Helicopter gunships Saturday pounded militant ...   \n",
       "3  They left after a tense hour-long standoff wit...   \n",
       "4  U.N. relief coordinator Jan Egeland said Sunda...   \n",
       "\n",
       "                                                 POS  \\\n",
       "0  NNS IN NNS VBP VBN IN NNP TO VB DT NN IN NNP C...   \n",
       "1  JJ NNS VBP PRP VBP TO VB NN TO JJ JJ NNS IN DT...   \n",
       "2  NN NNS NNP VBD JJ NNS IN DT NNP JJ NN , WRB JJ...   \n",
       "3                 PRP VBD IN DT NN JJ NN IN NN NNS .   \n",
       "4  NNP NN NN NNP NNP VBD NNP , NNP , JJ CC JJ JJ ...   \n",
       "\n",
       "                                                 Tag  \\\n",
       "0  O O O O O O B-geo O O O O O B-geo O O O O O B-...   \n",
       "1  B-gpe O O O O O O O O O O O O O O B-tim O O O ...   \n",
       "2  O O B-tim O O O O O B-geo O O O O O B-org O O ...   \n",
       "3                              O O O O O O O O O O O   \n",
       "4  B-geo O O B-per I-per O B-tim O B-geo O B-gpe ...   \n",
       "\n",
       "                                 tokenised_sentences  \\\n",
       "0  [Thousands, of, demonstrators, have, marched, ...   \n",
       "1  [Iranian, officials, say, they, expect, to, ge...   \n",
       "2  [Helicopter, gunships, Saturday, pounded, mili...   \n",
       "3  [They, left, after, a, tense, hour-long, stand...   \n",
       "4  [U.N., relief, coordinator, Jan, Egeland, said...   \n",
       "\n",
       "                                            tag_list  \n",
       "0  [O, O, O, O, O, O, B-geo, O, O, O, O, O, B-geo...  \n",
       "1  [B-gpe, O, O, O, O, O, O, O, O, O, O, O, O, O,...  \n",
       "2  [O, O, B-tim, O, O, O, O, O, B-geo, O, O, O, O...  \n",
       "3                  [O, O, O, O, O, O, O, O, O, O, O]  \n",
       "4  [B-geo, O, O, B-per, I-per, O, B-tim, O, B-geo...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_data['tokenised_sentences']=agg_data['Sentence'].apply(lambda x:x.split())\n",
    "agg_data['tag_list']=agg_data['Tag'].apply(lambda x:x.split())\n",
    "agg_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    47955\n",
       "0        4\n",
       "Name: is_equal, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_data['len_sentence']=agg_data['tokenised_sentences'].apply(lambda x:len(x))\n",
    "agg_data['len_tag']=agg_data['tag_list'].apply(lambda x:len(x))\n",
    "agg_data['is_equal']=agg_data.apply(lambda row:1 if row['len_sentence']==row['len_tag'] else 0,axis=1)\n",
    "agg_data['is_equal'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Sentence_POS_Tag_Pair</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "      <th>tokenised_sentences</th>\n",
       "      <th>tag_list</th>\n",
       "      <th>len_sentence</th>\n",
       "      <th>len_tag</th>\n",
       "      <th>is_equal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>[(Thousands, NNS, O), (of, IN, O), (demonstrat...</td>\n",
       "      <td>Thousands of demonstrators have marched throug...</td>\n",
       "      <td>NNS IN NNS VBP VBN IN NNP TO VB DT NN IN NNP C...</td>\n",
       "      <td>O O O O O O B-geo O O O O O B-geo O O O O O B-...</td>\n",
       "      <td>[Thousands, of, demonstrators, have, marched, ...</td>\n",
       "      <td>[O, O, O, O, O, O, B-geo, O, O, O, O, O, B-geo...</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 10</td>\n",
       "      <td>[(Iranian, JJ, B-gpe), (officials, NNS, O), (s...</td>\n",
       "      <td>Iranian officials say they expect to get acces...</td>\n",
       "      <td>JJ NNS VBP PRP VBP TO VB NN TO JJ JJ NNS IN DT...</td>\n",
       "      <td>B-gpe O O O O O O O O O O O O O O B-tim O O O ...</td>\n",
       "      <td>[Iranian, officials, say, they, expect, to, ge...</td>\n",
       "      <td>[B-gpe, O, O, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence: 100</td>\n",
       "      <td>[(Helicopter, NN, O), (gunships, NNS, O), (Sat...</td>\n",
       "      <td>Helicopter gunships Saturday pounded militant ...</td>\n",
       "      <td>NN NNS NNP VBD JJ NNS IN DT NNP JJ NN , WRB JJ...</td>\n",
       "      <td>O O B-tim O O O O O B-geo O O O O O B-org O O ...</td>\n",
       "      <td>[Helicopter, gunships, Saturday, pounded, mili...</td>\n",
       "      <td>[O, O, B-tim, O, O, O, O, O, B-geo, O, O, O, O...</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence: 1000</td>\n",
       "      <td>[(They, PRP, O), (left, VBD, O), (after, IN, O...</td>\n",
       "      <td>They left after a tense hour-long standoff wit...</td>\n",
       "      <td>PRP VBD IN DT NN JJ NN IN NN NNS .</td>\n",
       "      <td>O O O O O O O O O O O</td>\n",
       "      <td>[They, left, after, a, tense, hour-long, stand...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence: 10000</td>\n",
       "      <td>[(U.N., NNP, B-geo), (relief, NN, O), (coordin...</td>\n",
       "      <td>U.N. relief coordinator Jan Egeland said Sunda...</td>\n",
       "      <td>NNP NN NN NNP NNP VBD NNP , NNP , JJ CC JJ JJ ...</td>\n",
       "      <td>B-geo O O B-per I-per O B-tim O B-geo O B-gpe ...</td>\n",
       "      <td>[U.N., relief, coordinator, Jan, Egeland, said...</td>\n",
       "      <td>[B-geo, O, O, B-per, I-per, O, B-tim, O, B-geo...</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Sentence #                              Sentence_POS_Tag_Pair  \\\n",
       "0      Sentence: 1  [(Thousands, NNS, O), (of, IN, O), (demonstrat...   \n",
       "1     Sentence: 10  [(Iranian, JJ, B-gpe), (officials, NNS, O), (s...   \n",
       "2    Sentence: 100  [(Helicopter, NN, O), (gunships, NNS, O), (Sat...   \n",
       "3   Sentence: 1000  [(They, PRP, O), (left, VBD, O), (after, IN, O...   \n",
       "4  Sentence: 10000  [(U.N., NNP, B-geo), (relief, NN, O), (coordin...   \n",
       "\n",
       "                                            Sentence  \\\n",
       "0  Thousands of demonstrators have marched throug...   \n",
       "1  Iranian officials say they expect to get acces...   \n",
       "2  Helicopter gunships Saturday pounded militant ...   \n",
       "3  They left after a tense hour-long standoff wit...   \n",
       "4  U.N. relief coordinator Jan Egeland said Sunda...   \n",
       "\n",
       "                                                 POS  \\\n",
       "0  NNS IN NNS VBP VBN IN NNP TO VB DT NN IN NNP C...   \n",
       "1  JJ NNS VBP PRP VBP TO VB NN TO JJ JJ NNS IN DT...   \n",
       "2  NN NNS NNP VBD JJ NNS IN DT NNP JJ NN , WRB JJ...   \n",
       "3                 PRP VBD IN DT NN JJ NN IN NN NNS .   \n",
       "4  NNP NN NN NNP NNP VBD NNP , NNP , JJ CC JJ JJ ...   \n",
       "\n",
       "                                                 Tag  \\\n",
       "0  O O O O O O B-geo O O O O O B-geo O O O O O B-...   \n",
       "1  B-gpe O O O O O O O O O O O O O O B-tim O O O ...   \n",
       "2  O O B-tim O O O O O B-geo O O O O O B-org O O ...   \n",
       "3                              O O O O O O O O O O O   \n",
       "4  B-geo O O B-per I-per O B-tim O B-geo O B-gpe ...   \n",
       "\n",
       "                                 tokenised_sentences  \\\n",
       "0  [Thousands, of, demonstrators, have, marched, ...   \n",
       "1  [Iranian, officials, say, they, expect, to, ge...   \n",
       "2  [Helicopter, gunships, Saturday, pounded, mili...   \n",
       "3  [They, left, after, a, tense, hour-long, stand...   \n",
       "4  [U.N., relief, coordinator, Jan, Egeland, said...   \n",
       "\n",
       "                                            tag_list  len_sentence  len_tag  \\\n",
       "0  [O, O, O, O, O, O, B-geo, O, O, O, O, O, B-geo...            24       24   \n",
       "1  [B-gpe, O, O, O, O, O, O, O, O, O, O, O, O, O,...            25       25   \n",
       "2  [O, O, B-tim, O, O, O, O, O, B-geo, O, O, O, O...            32       32   \n",
       "3                  [O, O, O, O, O, O, O, O, O, O, O]            11       11   \n",
       "4  [B-geo, O, O, B-per, I-per, O, B-tim, O, B-geo...            35       35   \n",
       "\n",
       "   is_equal  \n",
       "0         1  \n",
       "1         1  \n",
       "2         1  \n",
       "3         1  \n",
       "4         1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Sentences in the Data  47959\n",
      "Are number of Sentences and Tag list equal  True\n"
     ]
    }
   ],
   "source": [
    "sentences_list=agg_data['Sentence'].tolist()\n",
    "tags_list=agg_data['tag_list'].tolist()\n",
    "\n",
    "print(\"Number of Sentences in the Data \",len(sentences_list))\n",
    "print(\"Are number of Sentences and Tag list equal \",len(sentences_list)==len(tags_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-geo',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-geo',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-gpe',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokeniser= tf.keras.preprocessing.text.Tokenizer(lower=False,filters='')\n",
    "\n",
    "tokeniser.fit_on_texts(sentences_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size of Tokeniser  35179\n"
     ]
    }
   ],
   "source": [
    "print(\"Vocab size of Tokeniser \",len(tokeniser.word_index)+1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'national'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokeniser.index_word[326]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Original Sentence  Thousands of demonstrators have marched through London to protest the war in Iraq and demand the withdrawal of British troops from that country .\n",
      "First Encoded Sentence  [1114, 4, 1161, 16, 1852, 229, 478, 6, 533, 1, 155, 5, 58, 8, 582, 1, 843, 4, 179, 87, 21, 15, 52, 2]\n",
      "Is Length of Original Sentence Same as Encoded Sentence  True\n",
      "Length of First Sentence  24\n"
     ]
    }
   ],
   "source": [
    "encoded_sentence=tokeniser.texts_to_sequences(sentences_list)\n",
    "print(\"First Original Sentence \",sentences_list[0])\n",
    "print(\"First Encoded Sentence \",encoded_sentence[0])\n",
    "print(\"Is Length of Original Sentence Same as Encoded Sentence \",len(sentences_list[0].split())==len(encoded_sentence[0]))\n",
    "print(\"Length of First Sentence \",len(encoded_sentence[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-art', 'B-org', 'B-gpe', 'O', 'B-per', 'I-tim', 'I-per', 'I-gpe', 'I-eve', 'I-org', 'B-tim', 'B-nat', 'B-geo', 'B-eve', 'B-art', 'I-nat', 'I-geo']\n",
      "Number of Tags  17\n",
      "Tags Map  {'I-art': 0, 'B-org': 1, 'B-gpe': 2, 'O': 3, 'B-per': 4, 'I-tim': 5, 'I-per': 6, 'I-gpe': 7, 'I-eve': 8, 'I-org': 9, 'B-tim': 10, 'B-nat': 11, 'B-geo': 12, 'B-eve': 13, 'B-art': 14, 'I-nat': 15, 'I-geo': 16}\n"
     ]
    }
   ],
   "source": [
    "tags=list(set(data['Tag'].values))\n",
    "print(tags)\n",
    "num_tags=len(tags)\n",
    "print(\"Number of Tags \",num_tags)\n",
    "\n",
    "tags_map={tag:i for i,tag in enumerate(tags)}\n",
    "print(\"Tags Map \",tags_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_tag_map={v: k for k, v in tags_map.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Sentence  Thousands of demonstrators have marched through London to protest the war in Iraq and demand the withdrawal of British troops from that country .\n",
      "First Sentence Original Tags  ['O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-gpe', 'O', 'O', 'O', 'O', 'O']\n",
      "First Sentence Encoded Tags  [3, 3, 3, 3, 3, 3, 12, 3, 3, 3, 3, 3, 12, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3]\n",
      "Is length of Original Tags and Encoded Tags same  True\n",
      "Length of Tags for First Sentence  24\n"
     ]
    }
   ],
   "source": [
    "encoded_tags=[[tags_map[w] for w in tag] for tag in tags_list]\n",
    "print(\"First Sentence \",sentences_list[0])\n",
    "print('First Sentence Original Tags ',tags_list[0])\n",
    "print(\"First Sentence Encoded Tags \",encoded_tags[0])\n",
    "print(\"Is length of Original Tags and Encoded Tags same \",len(tags_list[0])==len(encoded_tags[0]))\n",
    "print(\"Length of Tags for First Sentence \",len(encoded_tags[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104\n"
     ]
    }
   ],
   "source": [
    "max_sentence_length=max([len(s.split()) for s in sentences_list])\n",
    "print(max_sentence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Encoded Sentence  (47959, 128)\n",
      "Shape of Encoded Labels  (47959, 128)\n",
      "First Encoded Sentence Without Padding  [1114, 4, 1161, 16, 1852, 229, 478, 6, 533, 1, 155, 5, 58, 8, 582, 1, 843, 4, 179, 87, 21, 15, 52, 2]\n",
      "First Encoded Sentence with padding  [1114    4 1161   16 1852  229  478    6  533    1  155    5   58    8\n",
      "  582    1  843    4  179   87   21   15   52    2    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "First Sentence Encoded Label without Padding  [3, 3, 3, 3, 3, 3, 12, 3, 3, 3, 3, 3, 12, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3]\n",
      "First Sentence Encoded Label with Padding  [ 3  3  3  3  3  3 12  3  3  3  3  3 12  3  3  3  3  3  2  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3]\n"
     ]
    }
   ],
   "source": [
    "max_len=128\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "padded_encoded_sentences=pad_sequences(maxlen=max_len,sequences=encoded_sentence,padding=\"post\",value=0)\n",
    "padded_encoded_tags=pad_sequences(maxlen=max_len,sequences=encoded_tags,padding=\"post\",value=tags_map['O'])\n",
    "\n",
    "print(\"Shape of Encoded Sentence \",padded_encoded_sentences.shape)\n",
    "print(\"Shape of Encoded Labels \",padded_encoded_tags.shape)\n",
    "\n",
    "print(\"First Encoded Sentence Without Padding \",encoded_sentence[0])\n",
    "print(\"First Encoded Sentence with padding \",padded_encoded_sentences[0])\n",
    "print(\"First Sentence Encoded Label without Padding \",encoded_tags[0])\n",
    "print(\"First Sentence Encoded Label with Padding \",padded_encoded_tags[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Labels  after converting to Categorical for first sentence  (128, 17)\n"
     ]
    }
   ],
   "source": [
    "target= [to_categorical(i,num_classes = num_tags) for i in  padded_encoded_tags]\n",
    "print(\"Shape of Labels  after converting to Categorical for first sentence \",target[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Train Data Shape  (33571, 128)\n",
      "Train Labels Length  33571\n",
      "Input Test Data Shape  (2878, 128)\n",
      "Test Labels Length  2878\n",
      "Input Validation Data Shape  (11510, 128)\n",
      "Validation Labels Length  11510\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_val_test,y_train,y_val_test = train_test_split(padded_encoded_sentences,target,test_size = 0.3,random_state=42)\n",
    "X_val,X_test,y_val,y_test = train_test_split(X_val_test,y_val_test,test_size = 0.2,random_state=42)\n",
    "print(\"Input Train Data Shape \",X_train.shape)\n",
    "print(\"Train Labels Length \",len(y_train))\n",
    "print(\"Input Test Data Shape \",X_test.shape)\n",
    "print(\"Test Labels Length \",len(y_test))\n",
    "\n",
    "print(\"Input Validation Data Shape \",X_val.shape)\n",
    "print(\"Validation Labels Length \",len(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of First Sentence -Train (128,)\n",
      "Shape of First Sentence Label  -Train (128, 17)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of First Sentence -Train\",X_train[0].shape)\n",
    "print(\"Shape of First Sentence Label  -Train\",y_train[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model,Input\n",
    "from tensorflow.keras.layers import LSTM,Embedding,Dense\n",
    "from tensorflow.keras.layers import TimeDistributed, SpatialDropout1D,Bidirectional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1 LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 128)]             0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 128, 128)          4503040   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 128, 128)          131584    \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 128, 17)           2193      \n",
      "=================================================================\n",
      "Total params: 4,636,817\n",
      "Trainable params: 4,636,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_dim=128\n",
    "vocab_size=len(tokeniser.word_index)+1\n",
    "lstm_units=128\n",
    "max_len=128\n",
    "\n",
    "input_word = Input(shape = (max_len,))\n",
    "model = Embedding(input_dim = vocab_size+1,output_dim = embedding_dim,input_length = max_len)(input_word)\n",
    "\n",
    "model = LSTM(units=embedding_dim,return_sequences=True)(model)\n",
    "out = TimeDistributed(Dense(num_tags,activation = 'softmax'))(model)\n",
    "model = Model(input_word,out)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam',loss = 'categorical_crossentropy',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1050/1050 [==============================] - 45s 43ms/step - loss: 0.1022 - accuracy: 0.9809 - val_loss: 0.0353 - val_accuracy: 0.9912\n",
      "Epoch 2/3\n",
      "1050/1050 [==============================] - 44s 42ms/step - loss: 0.0253 - accuracy: 0.9930 - val_loss: 0.0245 - val_accuracy: 0.9930\n",
      "Epoch 3/3\n",
      "1050/1050 [==============================] - 43s 41ms/step - loss: 0.0180 - accuracy: 0.9945 - val_loss: 0.0229 - val_accuracy: 0.9931\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,np.array(y_train),validation_data=(X_val,np.array(y_val)),batch_size = 32,epochs = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds=model.predict(X_test) ## Predict using model on Test Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2 Bi-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 128)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 128, 128)          4503040   \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 128, 256)          263168    \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 128, 17)           4369      \n",
      "=================================================================\n",
      "Total params: 4,770,577\n",
      "Trainable params: 4,770,577\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_word2 = Input(shape = (max_len,))\n",
    "model2 = Embedding(input_dim = vocab_size+1,output_dim = embedding_dim,input_length = max_len)(input_word2)\n",
    "\n",
    "model2 = Bidirectional(LSTM(units=embedding_dim,return_sequences=True))(model2)\n",
    "out2 = TimeDistributed(Dense(num_tags,activation = 'softmax'))(model2)\n",
    "model2 = Model(input_word2,out2)\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(optimizer = 'adam',loss = 'categorical_crossentropy',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "1050/1050 [==============================] - 55s 52ms/step - loss: 0.0773 - accuracy: 0.9838 - val_loss: 0.0239 - val_accuracy: 0.9933\n",
      "Epoch 2/6\n",
      "1050/1050 [==============================] - 54s 51ms/step - loss: 0.0185 - accuracy: 0.9945 - val_loss: 0.0196 - val_accuracy: 0.9941\n",
      "Epoch 3/6\n",
      "1050/1050 [==============================] - 51s 49ms/step - loss: 0.0132 - accuracy: 0.9959 - val_loss: 0.0187 - val_accuracy: 0.9944\n",
      "Epoch 4/6\n",
      "1050/1050 [==============================] - 55s 52ms/step - loss: 0.0105 - accuracy: 0.9966 - val_loss: 0.0192 - val_accuracy: 0.9944\n",
      "Epoch 5/6\n",
      "1050/1050 [==============================] - 53s 50ms/step - loss: 0.0087 - accuracy: 0.9972 - val_loss: 0.0199 - val_accuracy: 0.9944\n",
      "Epoch 6/6\n",
      "1050/1050 [==============================] - 51s 49ms/step - loss: 0.0073 - accuracy: 0.9976 - val_loss: 0.0214 - val_accuracy: 0.9942\n"
     ]
    }
   ],
   "source": [
    "history2 = model2.fit(X_train,np.array(y_train),validation_data=(X_val,np.array(y_val)),batch_size = 32,epochs = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds2=model2.predict(X_test) ## Predict using model on Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluatePredictions(test_data,preds,actual_preds):\n",
    "    print(\"Shape of Test Data Array\",test_data.shape)\n",
    "    y_actual=np.argmax(np.array(actual_preds),axis=2)\n",
    "    y_pred=np.argmax(preds,axis=2)\n",
    "    num_test_data=test_data.shape[0]\n",
    "    print(\"Number of Test Data Points \",num_test_data)\n",
    "    data=pd.DataFrame()\n",
    "    df_list=[]\n",
    "    for i in range(num_test_data):\n",
    "        test_str=list(test_data[i])\n",
    "        df=pd.DataFrame()\n",
    "        df['test_tokens']=test_str\n",
    "        df['tokens']=df['test_tokens'].apply(lambda x:tokeniser.index_word[x] if x!=0 else '<PAD>')\n",
    "        df['actual_target_index']=list(y_actual[i])\n",
    "        df['pred_target_index']=list(y_pred[i])\n",
    "        df['actual_target_tag']=df['actual_target_index'].apply(lambda x:reverse_tag_map[x])\n",
    "        df['pred_target_tag']=df['pred_target_index'].apply(lambda x:reverse_tag_map[x])\n",
    "        df['id']=i+1\n",
    "        df_list.append(df)\n",
    "    data=pd.concat(df_list)\n",
    "    pred_data=data[data['tokens']!='<PAD>']\n",
    "    accuracy=pred_data[pred_data['actual_target_tag']==pred_data['pred_target_tag']].shape[0]/pred_data.shape[0]\n",
    "    \n",
    "    \n",
    "    return pred_data,accuracy\n",
    "        \n",
    "# pred_data[pred_data['actual_target_tag']==\"B-art\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Test Data Array (2878, 128)\n",
      "Number of Test Data Points  2878\n",
      "Shape of Test Data Array (2878, 128)\n",
      "Number of Test Data Points  2878\n"
     ]
    }
   ],
   "source": [
    "pred_data,accuracy=evaluatePredictions(X_test,preds,y_test)\n",
    "pred_data2,accuracy2=evaluatePredictions(X_test,preds2,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=pred_data['pred_target_tag'].tolist()\n",
    "y_actual=pred_data['actual_target_tag'].tolist()\n",
    "\n",
    "y_pred2=pred_data2['pred_target_tag'].tolist()\n",
    "y_actual2=pred_data2['actual_target_tag'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-art       0.00      0.00      0.00        27\n",
      "       B-eve       0.75      0.18      0.29        17\n",
      "       B-geo       0.78      0.90      0.83      2151\n",
      "       B-gpe       0.95      0.92      0.94       919\n",
      "       B-nat       0.00      0.00      0.00         5\n",
      "       B-org       0.78      0.52      0.63      1305\n",
      "       B-per       0.85      0.78      0.81      1062\n",
      "       B-tim       0.88      0.81      0.84      1197\n",
      "       I-art       0.00      0.00      0.00        30\n",
      "       I-eve       0.00      0.00      0.00        15\n",
      "       I-geo       0.71      0.79      0.75       413\n",
      "       I-gpe       0.00      0.00      0.00        11\n",
      "       I-org       0.81      0.72      0.76      1053\n",
      "       I-per       0.86      0.84      0.85      1066\n",
      "       I-tim       0.85      0.53      0.66       401\n",
      "           O       0.98      0.99      0.99     52763\n",
      "\n",
      "    accuracy                           0.96     62435\n",
      "   macro avg       0.57      0.50      0.52     62435\n",
      "weighted avg       0.96      0.96      0.96     62435\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhafran/miniconda3/envs/ai-labs/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_actual,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-art       0.25      0.07      0.11        27\n",
      "       B-eve       0.42      0.29      0.34        17\n",
      "       B-geo       0.83      0.89      0.86      2151\n",
      "       B-gpe       0.96      0.94      0.95       919\n",
      "       B-nat       0.14      0.20      0.17         5\n",
      "       B-org       0.82      0.64      0.72      1305\n",
      "       B-per       0.79      0.82      0.80      1062\n",
      "       B-tim       0.89      0.89      0.89      1197\n",
      "       I-art       0.18      0.07      0.10        30\n",
      "       I-eve       0.31      0.27      0.29        15\n",
      "       I-geo       0.76      0.78      0.77       413\n",
      "       I-gpe       0.86      0.55      0.67        11\n",
      "       I-nat       0.00      0.00      0.00         0\n",
      "       I-org       0.85      0.71      0.77      1053\n",
      "       I-per       0.85      0.87      0.86      1066\n",
      "       I-tim       0.76      0.79      0.77       401\n",
      "           O       0.99      0.99      0.99     52763\n",
      "\n",
      "    accuracy                           0.96     62435\n",
      "   macro avg       0.63      0.57      0.59     62435\n",
      "weighted avg       0.96      0.96      0.96     62435\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhafran/miniconda3/envs/ai-labs/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_actual2,y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
